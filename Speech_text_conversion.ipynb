{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "qqR0Mm9JLr44",
    "outputId": "fa9aca97-ba3c-4e15-974f-952a03f847f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils as utils\n",
    "from torch.nn.utils.rnn import *\n",
    "import pickle as pk\n",
    "from torchnlp.nn import WeightDrop , LockedDropout\n",
    "from torch.utils.data import DataLoader, Dataset \n",
    "from torch.distributions.gumbel import Gumbel\n",
    "from torchnlp.nn import LockedDropout\n",
    "import time\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bQbL0RweIvHr"
   },
   "source": [
    "# **Load data**\n",
    "\n",
    "Loading all the numpy files containing the utterance information and text information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "lK3YBjyBNaBM",
    "outputId": "bcfc59d0-9967-47dd-9154-905dc96c6c8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loading Sucessful.....\n"
     ]
    }
   ],
   "source": [
    "speech_train = np.load('train_new.npy', allow_pickle=True, encoding='bytes')\n",
    "speech_valid = np.load('dev_new.npy', allow_pickle=True, encoding='bytes')\n",
    "speech_test = np.load('test_new.npy', allow_pickle=True, encoding='bytes')\n",
    "\n",
    "transcript_train = np.load('./train_transcripts.npy', allow_pickle=True,encoding='bytes')\n",
    "transcript_valid = np.load('./dev_transcripts.npy', allow_pickle=True,encoding='bytes')\n",
    "print(\"Data Loading Sucessful.....\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([b'THE', b'FEMALE', b'PRODUCES', b'A', b'LITTER', b'OF', b'TWO',\n",
      "       b'TO', b'FOUR', b'YOUNG', b'IN', b'NOVEMBER', b'AND', b'DECEMBER'],\n",
      "      dtype='|S8')\n",
      " array([b'NUMEROUS', b'WORKS', b'OF', b'ART', b'ARE', b'BASED', b'ON',\n",
      "       b'THE', b'STORY', b'OF', b'THE', b'SACRIFICE', b'OF', b'ISAAC'],\n",
      "      dtype='|S9')\n",
      " array([b'THEIR', b'SOLUTION', b'REQUIRES', b'DEVELOPMENT', b'OF', b'THE',\n",
      "       b'HUMAN', b'CAPACITY', b'FOR', b'SOCIAL', b'INTEREST'],\n",
      "      dtype='|S11')\n",
      " ...\n",
      " array([b'AND', b'IT', b'HAPPENED', b'PERIOD', b'DOUBLE-QUOTE'],\n",
      "      dtype='|S12')\n",
      " array([b'THE', b'HOUSE', b'SO', b'FAR', b'HAS', b'PROPOSED', b'A',\n",
      "       b'LOAN', b'HYPHEN', b'GUARANTEE', b'BUDGET', b'OF', b'ONLY',\n",
      "       b'TWO', b'POINT', b'FOUR', b'BILLION', b'DOLLARS', b'COMMA',\n",
      "       b'BUT', b'BACKERS', b'ARE', b'PRESSING', b'FOR', b'MORE',\n",
      "       b'PERIOD'], dtype='|S9')\n",
      " array([b'DOUBLE-QUOTE', b\"HAVEN'T\", b'WE', b'ALREADY', b'GONE',\n",
      "       b'OVERBOARD', b'IN', b'S.', b'B.', b'A.', b'BUDGET', b'CUTS',\n",
      "       b'QUESTION-MARK', b'DOUBLE-QUOTE'], dtype='|S13')]\n"
     ]
    }
   ],
   "source": [
    "print(transcript_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(speech_valid[4].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BtTaq7LTJh4R"
   },
   "source": [
    "# **Transform Text Data**\n",
    "\n",
    "`transform_letter_to_index` function transforms alphabetical input to numerical input. Each letter is replaced by its corresponding index from `letter_list` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xsweiPx1JCk4"
   },
   "outputs": [],
   "source": [
    "letter_list = ['<sos>','<eos>','A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q',\\\n",
    "             'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '-', \"'\", '.', '_', '+', ' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P2us4QQFJgBA"
   },
   "outputs": [],
   "source": [
    "def transform_letter_to_index(transcript, letter_list):\n",
    "    '''\n",
    "    :param transcript :(N, ) Transcripts are the text input\n",
    "    :param letter_list: Letter list defined above\n",
    "    :return letter_to_index_list: Returns a list for all the transcript sentence to index\n",
    "    '''\n",
    "    output_list=[]\n",
    "    letter_index_list = np.arange(len(letter_list))\n",
    "\n",
    "    for i in range(transcript.shape[0]):\n",
    "        \n",
    "        sentence = transcript[i]\n",
    "        sentence = np.array(sentence , dtype=str)\n",
    "        temp=\" \".join(list(sentence))\n",
    "\n",
    "        sentence_list = [letter_index_list[0]+1]\n",
    "        \n",
    "        for j in range(len(temp)):\n",
    "            \n",
    "            sentence_list.append(letter_list.index(temp[j])+1)\n",
    "\n",
    "        sentence_list.append(letter_index_list[1]+1)\n",
    "\n",
    "        output_list.append(sentence_list)\n",
    "    \n",
    "    return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "hgQhXBkFJgUE",
    "outputId": "80581611-80c6-4b0d-b9bf-f3fa3e28f6f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed data sucessfully.....\n"
     ]
    }
   ],
   "source": [
    "character_text_train = transform_letter_to_index(transcript_train, letter_list)\n",
    "character_text_valid = transform_letter_to_index(transcript_valid, letter_list)\n",
    "\n",
    "print(\"Transformed data sucessfully.....\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 22, 10, 7, 34, 8, 7, 15, 3, 14, 7, 34, 18, 20, 17, 6, 23, 5, 7, 21, 34, 3, 34, 14, 11, 22, 22, 7, 20, 34, 17, 8, 34, 22, 25, 17, 34, 22, 17, 34, 8, 17, 23, 20, 34, 27, 17, 23, 16, 9, 34, 11, 16, 34, 16, 17, 24, 7, 15, 4, 7, 20, 34, 3, 16, 6, 34, 6, 7, 5, 7, 15, 4, 7, 20, 2]\n"
     ]
    }
   ],
   "source": [
    "print(character_text_valid[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KRhKPu8kMIJ7"
   },
   "source": [
    "\n",
    "# **Pyramidal BiLSTM**\n",
    " \n",
    "\n",
    "*   The length of utterance (speech input) can be hundereds to thousands of frames long.\n",
    "*   Paper reports that that a direct LSTM implementation as Encoder resulted in slow convergence and inferior results even after extensive training.\n",
    "*   The major reason is inability of `AttendAndSpell` operation to extract relevant information from a large number of input steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cVpvqoT9iCZW"
   },
   "outputs": [],
   "source": [
    "\n",
    "class pBLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(pBLSTM, self).__init__()\n",
    "        self.blstm = nn.LSTM(input_size=input_dim,hidden_size=hidden_dim,num_layers=1,bidirectional=True)\n",
    "        self.do1=nn.Dropout(0.2)\n",
    "    \n",
    "    def forward(self,x,new_length_list , train):\n",
    "#     '''\n",
    "#     :param x :(N,T) input to the pBLSTM\n",
    "#     :return output: (N,T,H) encoded sequence from pyramidal Bi-LSTM \n",
    "#     '''\n",
    "        outputs1, _ = utils.rnn.pad_packed_sequence(x)\n",
    "        if(outputs1.size(0)%2!=0):\n",
    "            outputs1 = outputs1[:outputs1.size(0)-1,:,:]\n",
    "        new_length1 = int(outputs1.shape[0]/2)\n",
    "        batch_size1 = outputs1.shape[1]\n",
    "        freq_size1= outputs1.shape[2]\n",
    "        i_plstm1 = outputs1.transpose(0,1)\n",
    "        i_plstm1 = i_plstm1.reshape(batch_size1,new_length1,freq_size1*2)\n",
    "        i_plstm1 = i_plstm1.transpose(0,1)\n",
    "        #new_length_list=np.array(list(lens))/2\n",
    "        \n",
    "        \n",
    "        rnn_inp1 = utils.rnn.pack_padded_sequence(i_plstm1, lengths=new_length_list, batch_first=False, enforce_sorted=False)\n",
    "        \n",
    "        output,_ = self.blstm(rnn_inp1)\n",
    "        if(train):\n",
    "            temp,_ = utils.rnn.pad_packed_sequence(output)\n",
    "            temp1=self.do1(temp)\n",
    "            output = utils.rnn.pack_padded_sequence(temp1, lengths=new_length_list, batch_first=False, enforce_sorted=False)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Ca-GREENqrO"
   },
   "source": [
    "# **Encoder**\n",
    "\n",
    "*    Encoder takes the utterances as inputs and returns the key and value.\n",
    "*    Key and value are nothing but simple projections of the output from pBLSTM network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rt-CxFPGuOw-"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, value_size=128,key_size=128):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=input_dim,hidden_size=hidden_dim,num_layers=1,bidirectional=True)\n",
    "        #Here you need to define the blocks of pBLSTMs\n",
    "    \n",
    "        self.plstm1 = pBLSTM(hidden_dim*4,hidden_dim)\n",
    "        self.plstm2 = pBLSTM(hidden_dim*4,hidden_dim)\n",
    "        self.plstm3 = pBLSTM(hidden_dim*4,hidden_dim)\n",
    "        \n",
    "        self.do1=LockedDropout(0.2)\n",
    "        self.do2=LockedDropout(0.2)\n",
    "        self.do3=LockedDropout(0.2)\n",
    "    \n",
    "        self.key_network = nn.Linear(hidden_dim*2, value_size)\n",
    "        self.value_network = nn.Linear(hidden_dim*2, key_size)\n",
    "  \n",
    "    def forward(self,x, lens,train):\n",
    "        \n",
    "        rnn_inp = utils.rnn.pack_padded_sequence(x, lengths=lens, batch_first=False, enforce_sorted=False)\n",
    "        outputs, _ = self.lstm(rnn_inp)\n",
    "\n",
    "\n",
    "        length = np.array(list(lens))\n",
    "\n",
    "        o_plstm1=self.plstm1(outputs,length//2 , train)\n",
    "        o_plstm2=self.plstm2(o_plstm1,length//4 , train)\n",
    "        o_plstm3=self.plstm3(o_plstm2,length//8 , train)\n",
    "        \n",
    "        linear_input, _ = utils.rnn.pad_packed_sequence(o_plstm3)\n",
    "\n",
    "        keys = self.key_network(linear_input)\n",
    "        value = self.value_network(linear_input)\n",
    "        \n",
    "        new_length_list1 = length//8\n",
    "\n",
    "        return keys, value, new_length_list1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z7CdGLzuOvKx"
   },
   "source": [
    "# **Attention**\n",
    "\n",
    "*    Attention is calculated using key, value and query from Encoder and decoder.\n",
    "\n",
    "Below are the set of operations you need to perform for computing attention.\n",
    "\n",
    "```\n",
    "energy = bmm(key, query)\n",
    "attention = softmax(energy)\n",
    "context = bmm(attention, value)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W5vsgAUyzdjh"
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Attention, self).__init__()\n",
    "  def forward(self, query, key, value, lens):\n",
    "    '''\n",
    "    :param query :(N,context_size) Query is the output of LSTMCell from Decoder\n",
    "    :param key: (T,N,key_size) Key Projection from Encoder per time step\n",
    "    :param value: (T,N,value_size) Value Projection from Encoder per time step\n",
    "    :return output: Attended Context\n",
    "    :return attention_mask: Attention mask that can be plotted  \n",
    "    '''\n",
    "\n",
    "    key = key.transpose(0, 1)\n",
    "    value = value.transpose(0, 1)\n",
    "    lens = torch.LongTensor(lens)\n",
    "\n",
    "    energy = torch.bmm(key, query.unsqueeze(2)).squeeze(2)\n",
    "\n",
    "    mask = torch.arange(key.size(1)).unsqueeze(0) >= lens.unsqueeze(1)\n",
    "\n",
    "    mask = mask.to(device)\n",
    "    \n",
    "    energy.masked_fill_(mask, -1e9)\n",
    "\n",
    "\n",
    "    attention = nn.functional.softmax(energy, dim=1)\n",
    "\n",
    "    context = torch.bmm(attention.unsqueeze(1), value).squeeze(1)\n",
    "\n",
    "    \n",
    "    return context\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A24z9vjsPrSP"
   },
   "source": [
    "# **Decoder**\n",
    "\n",
    "*    As mentioned in Recitation-9 each forward call of decoder deals with just one time step. Thus we use LSTMCell instead of LSLTM here.\n",
    "*    Output from the second LSTMCell can be used as query here for attention module.\n",
    "*    In place of `value` that we get from the attention, this can be replace by context we get from the attention.\n",
    "*    Methods like Gumble noise and teacher forcing can also be incorporated for improving the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ze3vySn38YsC"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Decoder(nn.Module):\n",
    "  def __init__(self, vocab_size, hidden_dim, value_size=128, key_size=128,  isAttended=False):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.embedding = nn.Embedding(vocab_size, hidden_dim)\n",
    "\n",
    "    \n",
    "    self.lstm1 = nn.LSTMCell(input_size=hidden_dim+value_size, hidden_size=hidden_dim)\n",
    "    \n",
    "    self.do1= nn.Dropout(0.2)\n",
    "    self.do2= nn.Dropout(0.2)\n",
    "    \n",
    "    self.lstm2 = nn.LSTMCell(input_size=hidden_dim, hidden_size=key_size)\n",
    "\n",
    "    self.isAttended = isAttended\n",
    "    if(isAttended):\n",
    "      self.attention = Attention()\n",
    "    self.character_prob = nn.Linear(key_size+value_size,vocab_size)\n",
    "\n",
    "  def forward(self, key, values,input_length,rate, text=None, train=True):\n",
    "    '''\n",
    "    :param key :(T,N,key_size) Output of the Encoder Key projection layer\n",
    "    :param values: (T,N,value_size) Output of the Encoder Value projection layer\n",
    "    :param text: (N,text_len) Batch input of text with text_length\n",
    "    :param train: Train or eval mode\n",
    "    :return predictions: Returns the character perdiction probability \n",
    "    '''\n",
    "    batch_size = key.shape[1]\n",
    "    if(train):\n",
    "      max_len =  text.shape[1]-1\n",
    "      embeddings = self.embedding(text)\n",
    "    else:\n",
    "      max_len = 250\n",
    "    \n",
    "    predictions = []\n",
    "    hidden_states = [None, None]\n",
    "    \n",
    "    \n",
    "    prediction = torch.zeros(batch_size,1).to(device)\n",
    "    \n",
    "    x_att = values[0,:,:]\n",
    "\n",
    "    gumbel_rate =0.1\n",
    "\n",
    "    for i in range(max_len):\n",
    "      '''\n",
    "      Here you should implement Gumble noise and teacher forcing techniques\n",
    "      '''\n",
    "      teacher_forcing_choice = np.random.choice([0,1],p=[rate,1-rate])\n",
    "        \n",
    "      if(train):\n",
    "        if(teacher_forcing_choice==0):\n",
    "                prediction1= Gumbel(prediction.cpu() ,torch.FloatTensor([gumbel_rate])).sample().to(device)\n",
    "                 \n",
    "                char_embed = self.embedding(prediction1.argmax(dim=-1))\n",
    "\n",
    "        char_embed = embeddings[:,i,:]\n",
    "\n",
    "      else:\n",
    "        \n",
    "        if(i==0):\n",
    "            \n",
    "            char_embed = self.embedding(torch.tensor([1]).to(device))\n",
    "        \n",
    "        else:\n",
    "         \n",
    "            char_embed = self.embedding(prediction.argmax(dim=-1))\n",
    "    \n",
    "      \n",
    "      \n",
    "      #When attention is True you should replace the values[i,:,:] with the context you get from attention\n",
    "      \n",
    "      inp = torch.cat([char_embed,x_att], dim=1)\n",
    "      if(train):\n",
    "        \n",
    "        hidden_states[0] = self.lstm1(inp,hidden_states[0])\n",
    "        o1 = self.do1(hidden_states[0][0])\n",
    "        \n",
    "        hidden_states[1] = self.lstm2(o1,hidden_states[1])\n",
    "        output = self.do2(hidden_states[1][0])\n",
    "      else:  \n",
    "      \n",
    "        hidden_states[0] = self.lstm1(inp,hidden_states[0])\n",
    "\n",
    "        inp_2 = hidden_states[0][0]\n",
    "        hidden_states[1] = self.lstm2(inp_2,hidden_states[1])\n",
    "\n",
    "        output = hidden_states[1][0]\n",
    "      \n",
    "      x_att = self.attention(output,key,values,input_length)\n",
    "      prediction = self.character_prob(torch.cat([output, x_att], dim=1))\n",
    "      predictions.append(prediction.unsqueeze(1))\n",
    "\n",
    "    return torch.cat(predictions, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zDDrRnxtQw5_"
   },
   "source": [
    "# **Sequence to Sequence Model**\n",
    "\n",
    "*    We train an end-to-end sequence to sequence model comprising of Encoder and Decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VkYfmPMdh5Bx"
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self,input_dim,vocab_size,hidden_dim,value_size=128, key_size=128,isAttended=False):\n",
    "        super(Seq2Seq,self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(input_dim, hidden_dim)\n",
    "        self.decoder = Decoder(vocab_size, hidden_dim*2, isAttended=isAttended)\n",
    "    def forward(self,speech_input, speech_len, rate, text_input=None,train=True):\n",
    "        key, value,new_length_list = self.encoder(speech_input, speech_len , train=train)\n",
    "        \n",
    "        if(train):\n",
    "              predictions = self.decoder(key, value, rate=rate, text=text_input,input_length=new_length_list)\n",
    "        else:\n",
    "              predictions = self.decoder(key, value, rate=rate, text=None, train=False, input_length=new_length_list)\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T16pOYYsTnpj"
   },
   "source": [
    "# **DataLoader**\n",
    "\n",
    "Below is the dataloader for the homework.\n",
    "\n",
    "*    You are expected to fill in the collate function if you use this code skeleton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TQCGXuERKHj0"
   },
   "outputs": [],
   "source": [
    "class Speech2Text_Dataset(Dataset):\n",
    "    def __init__(self, speech, text=None, train=True):\n",
    "        self.speech = speech\n",
    "        self.train = train\n",
    "        if(text is not None):\n",
    "              self.text = text\n",
    "    def __len__(self):\n",
    "        return self.speech.shape[0]\n",
    "    def __getitem__(self, index):\n",
    "        if(self.train):\n",
    "              return torch.tensor(self.speech[index].astype(np.float32)), torch.tensor(self.text[index])\n",
    "        else:\n",
    "              return torch.tensor(self.speech[index].astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NcP6ruJWQE0r"
   },
   "outputs": [],
   "source": [
    "def collate_train(batch_data):\n",
    "    \n",
    "#   '''\n",
    "#   Complete this function.\n",
    "#   I usually return padded speech and text data, and length of \n",
    "#   utterance and transcript from this function \n",
    "#   '''\n",
    "    inputs,targets = zip(*batch_data)\n",
    "    \n",
    "    X=inputs\n",
    "    \n",
    "    Y=targets\n",
    "    \n",
    "    #print(X)\n",
    "    \n",
    "    X1=[]\n",
    "        \n",
    "    Y1=[]\n",
    "        \n",
    "    X_lens=[]\n",
    "\n",
    "    Y_lens=[]\n",
    "    \n",
    "    utterances = len(X)\n",
    "\n",
    "    for i in range(len(X)):\n",
    "\n",
    "        X1.append(torch.FloatTensor(X[i]))\n",
    "    \n",
    "        Y1.append(torch.LongTensor(Y[i]))\n",
    "    \n",
    "        X_lens.append(X[i].shape[0])\n",
    "    \n",
    "        Y_lens.append(Y[i].shape[0])\n",
    "        \n",
    "    max_time_frame_length = max(X_lens)\n",
    "        \n",
    "    X2 = torch.zeros((len(X) , max_time_frame_length, 40))\n",
    "        \n",
    "    for i in range(len(X)):\n",
    "    \n",
    "        X2[i,:X_lens[i],:] = X1[i]\n",
    "        \n",
    "    seq_lengths = torch.LongTensor(X_lens)\n",
    "    \n",
    "    X = X2.transpose(0,1)\n",
    "        \n",
    "    max_Y_length = max(Y_lens)\n",
    "        \n",
    "    Y2 = torch.zeros((utterances , max_Y_length))\n",
    "        \n",
    "    for i in range(utterances):\n",
    "        \n",
    "        Y2[i,:Y_lens[i]] = Y1[i]\n",
    "        \n",
    "    seq_lengths_Y = torch.LongTensor(Y_lens)\n",
    "    \n",
    "    Y = Y2\n",
    " \n",
    "    X_length = tuple(seq_lengths.tolist())\n",
    "    \n",
    "    Y_length = tuple(seq_lengths_Y.tolist())\n",
    "    \n",
    "    return X, Y , X_length, Y_length \n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_test(batch_data):\n",
    "  '''\n",
    "  Complete this function.\n",
    "  I usually return padded speech and length of\n",
    "  utterance from this function\n",
    "  '''\n",
    "  inputs = batch_data\n",
    "  #print(inputs)\n",
    "  input_lens = [len(seq) for seq in inputs]\n",
    "  inputs = [torch.tensor(l) for l in inputs]\n",
    "  inputs = pad_sequence(inputs)\n",
    "  return inputs.to(device), tuple(input_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ndp6GoOwbexP"
   },
   "outputs": [],
   "source": [
    "Speech2Text_train_Dataset = Speech2Text_Dataset(speech_train, character_text_train)\n",
    "Speech2Text_test_Dataset = Speech2Text_Dataset(speech_test, None, False)\n",
    "Speech2Text_valid_Dataset = Speech2Text_Dataset(speech_valid, None,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8mam6qQ9vAMh"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(Speech2Text_train_Dataset, batch_size=64, shuffle=True, collate_fn=collate_train)\n",
    "valid_loader = DataLoader(Speech2Text_valid_Dataset, batch_size=1, shuffle=False, collate_fn=collate_test)\n",
    "test_loader = DataLoader(Speech2Text_test_Dataset, batch_size=1, shuffle=False, collate_fn=collate_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7nTBl9L9UA_Y"
   },
   "source": [
    "# **Learning**\n",
    "\n",
    "Defining the Sequence to Sequence model, optimizer and criterion for learning.\n",
    "\n",
    "Train routine is also provided here which can be referenced while writing validation and test routine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "      \n",
    "      if 'weight' in name:\n",
    "         nn.init.xavier_normal_(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gYCNa25wvI1J"
   },
   "outputs": [],
   "source": [
    "model = Seq2Seq(input_dim=40,vocab_size=len(letter_list)+1,hidden_dim=256,isAttended=True)\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss(reduction='none').to(device)\n",
    "model.apply(init_weights)\n",
    "start_epoch=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/ubuntu/hw4part2/'\n",
    "checkpoint = torch.load(path + \"model_params_256gumbel15.tar\")   \n",
    "model.cuda()\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "start_epoch = checkpoint['epoch']+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HNksqnudkbg7"
   },
   "outputs": [],
   "source": [
    "path = '/home/ubuntu/hw4part2/'\n",
    "def train(model,train_loader, num_epochs, criterion, optimizer):\n",
    "  rate=0.1*(1.05)\n",
    "  for epochs in range(start_epoch,num_epochs):\n",
    "    loss_sum = 0\n",
    "    since = time.time()\n",
    "    print(\"Epochs:\",epochs)\n",
    "    \n",
    "    for (batch_num, collate_output) in enumerate(train_loader):\n",
    "      with torch.autograd.set_detect_anomaly(True):\n",
    "        \n",
    "        speech_input, text_input, speech_len, text_len = collate_output\n",
    "        text_input = text_input.long()\n",
    "        speech_input = speech_input.to(device)\n",
    "        '''\n",
    "        Please check if the text_input is of the (Batch_size, Sequence_length) i.e. (B,L)\n",
    "        '''\n",
    "        text_input = text_input.to(device)\n",
    "\n",
    "        predictions = model(speech_input= speech_input, speech_len=speech_len ,text_input=text_input, rate=rate)\n",
    "       \n",
    "        mask = torch.zeros(text_input.size()).to(device)\n",
    "\n",
    "        for i in range(len(text_len)):\n",
    "\n",
    "          mask[i,:text_len[i]] = 1\n",
    "        \n",
    "        mask = mask[:,1:]\n",
    "        \n",
    "        mask = mask.reshape(-1).to(device)\n",
    "        \n",
    "\n",
    "\n",
    "        predictions = predictions.contiguous().view(-1, predictions.size(-1))\n",
    "        '''\n",
    "        If you do not have text_input as (B,L) but have (L,B) instead then make\n",
    "        sure that you uncomment the next line of code\n",
    "        '''\n",
    "\n",
    "        text_input = text_input[:,1:]\n",
    "        \n",
    "        batch_size = text_input.shape[0]\n",
    "\n",
    "       \n",
    "        text_input = text_input.contiguous().view(-1)\n",
    "\n",
    "        loss = criterion(predictions, text_input)\n",
    "\n",
    "        masked_loss = torch.sum(loss*mask)\n",
    "\n",
    "        masked_loss1 = masked_loss /(sum(text_len) - batch_size)\n",
    "\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        masked_loss1.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm(model.parameters(), 2)\n",
    "        optimizer.step()\n",
    "\n",
    "        current_loss = float(masked_loss.item())/int(torch.sum(mask).item())\n",
    "\n",
    "        if  batch_num % 25 == 1:\n",
    "          print('train_loss', current_loss)\n",
    "          print(\"perplexity\",np.exp(masked_loss1.cpu().detach().numpy()))\n",
    "            \n",
    "    if(rate < 0.4):\n",
    "        rate = rate*1.05\n",
    "        \n",
    "    torch.save({\n",
    "        'epoch': epochs,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': current_loss,\n",
    "        },path + \"model_params_gumbel\" + str(epochs) + \".tar\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sVnvrWJcvwEN"
   },
   "outputs": [],
   "source": [
    "train(model, train_loader, 30, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08902769749237045\n"
     ]
    }
   ],
   "source": [
    "path = '/home/ubuntu/hw4part2/'\n",
    "path1= '/home/ubuntu/hw4part2/withoutgumbel/'\n",
    "checkpoint = torch.load(path + \"model_params_256gumbel15.tar\")   \n",
    "model.cuda()\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "print(checkpoint['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,test_loader,criterion, optimizer):\n",
    "     output_list=[]\n",
    "    \n",
    "     for (batch_num, collate_output) in enumerate(test_loader):\n",
    "        \n",
    "            #speech_input, a , speech_len, b = collate_output\n",
    "            speech_input,speech_len = collate_output\n",
    "            speech_input = speech_input.to(device)\n",
    "            #print(speech_input.size())\n",
    "            predictions = model(speech_input, speech_len,train=False, rate=0.1)\n",
    "            predictions = predictions.contiguous().view(-1, predictions.size(-1))\n",
    "            #print(predictions.size())\n",
    "            out_token = torch.argmax(predictions,dim=-1)\n",
    "            #print(out_token)\n",
    "            letter_list1= np.array(letter_list)\n",
    "            #print(letter_list1[out_token.cpu()-1].shape)\n",
    "            sentence = \"\".join(letter_list1[out_token.cpu()-1])\n",
    "            #print(sentence)\n",
    "            if('<eos>' in sentence):\n",
    "                 \n",
    "                 stop_index=sentence.index('<eos>')\n",
    "                 sentence = sentence[:stop_index]\n",
    "\n",
    "            print(sentence)\n",
    "            output_list.append(sentence)\n",
    "            \n",
    "\n",
    "        \n",
    "     return output_list       \n",
    "            \n",
    "\n",
    "    \n",
    "    \n",
    "output_list = test(model,test_loader,criterion,optimizer)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "path ='/home/ubuntu/hw4part2/'\n",
    "ids=np.arange(523).reshape(523,1)\n",
    "string_list = np.array(output_list).reshape(523,1)\n",
    "np.savetxt(path + \"outputsubmissiongumbel15_epoch.csv\", string_list, delimiter=',',fmt=\"%s\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Recitation11_code.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
